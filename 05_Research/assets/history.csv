Name,Date,Link,Authors,Title,Hide,New,Type,Parameters,Summary
LSTM,1997-11-01,http://www.bioinf.jku.at/publications/older/2604.pdf,,,1,0,Autoregressive / Transformer,,
VAE,2013-12-20,https://arxiv.org/abs/1312.6114,"Diederik P Kingma, Max Welling","Auto-Encoding Variational Bayes",0,0,Variational Autoencoder,,
Encoder Decoder,2014-06-03,https://arxiv.org/abs/1406.1078,"Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio",Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,1,0,Autoregressive / Transformer,,
GAN,2014-06-10,https://arxiv.org/abs/1406.2661,,,0,0,Generative Adversarial Network,,
Attention,2014-09-01,https://arxiv.org/abs/1409.0473,"Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio",Neural Machine Translation by Jointly Learning to Align and Translate,1,0,General,,
GRU,2014-09-03,https://arxiv.org/abs/1409.1259,,,0,0,Autoregressive / Transformer,,
CGAN,2014-11-06,https://arxiv.org/abs/1411.1784,,,0,0,Generative Adversarial Network,,
Diffusion Process,2015-03-12,https://arxiv.org/abs/1503.03585,,,1,0,Energy-Based / Diffusion Models,,
UNet,2015-05-18,https://arxiv.org/abs/1505.04597,,,0,0,General,,
Neural Style,2015-08-26,https://arxiv.org/abs/1508.06576,,,1,0,General,,
DCGAN,2015-11-19,https://arxiv.org/abs/1511.06434,,,0,0,Generative Adversarial Network,,
ResNet,2015-12-10,https://arxiv.org/abs/1512.03385,,,0,0,General,,
VAE-GAN,2015-12-31,https://arxiv.org/abs/1512.09300,,,0,0,Variational Autoencoder,,
Self Attention,2016-01-25,https://arxiv.org/abs/1601.06733,,,1,0,Autoregressive / Transformer,,
PixelRNN,2016-01-25,https://arxiv.org/abs/1601.06759,,,0,0,Autoregressive / Transformer,,
RealNVP,2016-05-27,https://arxiv.org/abs/1605.08803v3,,,0,0,Normalizing Flow,,
PixelCNN,2016-06-16,https://arxiv.org/abs/1606.05328,,,0,0,Autoregressive / Transformer,,
pix2pix,2016-11-21,https://arxiv.org/abs/1611.07004,,,0,0,Generative Adversarial Network,,
Stack GAN,2016-12-10,https://arxiv.org/abs/1612.03242,,,1,0,Generative Adversarial Network,,
PixelCNN++,2017-01-19,https://arxiv.org/abs/1701.05517,,,0,0,Autoregressive / Transformer,,
WGAN,2017-01-26,https://arxiv.org/abs/1701.07875,,,0,0,Generative Adversarial Network,,
CycleGAN,2017-03-30,https://arxiv.org/abs/1703.10593,,,0,0,Generative Adversarial Network,,
WGAN GP,2017-03-31,https://arxiv.org/abs/1704.00028,,,1,0,Generative Adversarial Network,,
Transformers,2017-06-12,https://arxiv.org/abs/1706.03762,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",Attention Is All You Need,0,0,Autoregressive / Transformer,,
MuseGAN,2017-09-19,https://arxiv.org/abs/1709.06298,,,0,0,Generative Adversarial Network,,
ProGAN,2017-10-27,https://arxiv.org/abs/1710.10196,,,0,0,Generative Adversarial Network,,
VQ-VAE,2017-11-02,https://arxiv.org/abs/1711.00937v2,,,0,0,Variational Autoencoder,,
ULMFiT,2018-01-18,https://arxiv.org/abs/1801.06146,"Jeremy Howard, Sebastian Ruder",Universal Language Model Fine-tuning for Text Classification,0,1,Autoregressive / Transformer,,
ELMo,2018-02-15,https://arxiv.org/abs/1802.05365,"Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer",Deep contextualized word representations,0,1,Autoregressive / Transformer,,
World Models,2018-03-27,https://arxiv.org/abs/1803.10122,,,0,0,Variational Autoencoder,,
SAGAN,2018-05-21,https://arxiv.org/abs/1805.08318v2,,,0,0,Generative Adversarial Network,,
GPT,2018-06-11,https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf,"Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever",Improving Language Understanding by Generative Pre-Training,0,0,Autoregressive / Transformer,0.117,
GLOW,2018-07-09,https://arxiv.org/abs/1807.03039,,,0,0,Normalizing Flow,,
Universal Transformer,2018-07-10,https://arxiv.org/abs/1807.03819,,,1,0,Autoregressive / Transformer,,
BigGAN,2018-09-28,https://arxiv.org/abs/1809.11096,,,0,0,Generative Adversarial Network,,
FFJORD,2018-10-02,https://arxiv.org/abs/1810.01367,,,0,0,Normalizing Flow,,
BERT,2018-10-11,https://arxiv.org/abs/1810.04805,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,0,0,Autoregressive / Transformer,0.345,
StyleGAN,2018-12-12,https://arxiv.org/abs/1812.04948,,,0,0,Generative Adversarial Network,,
Music Transformer,2018-12-12,https://arxiv.org/abs/1809.04281,,,0,0,Autoregressive / Transformer,,
GPT-2,2019-02-14,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf,,,0,0,Autoregressive / Transformer,1.5,
MuseNet,2019-04-25,https://openai.com/blog/musenet/,,,0,0,Autoregressive / Transformer,,
VQ-VAE-2,2019-06-02,https://arxiv.org/abs/1906.00446v1,,,0,0,Variational Autoencoder,,
NCSN,2019-07-12,https://arxiv.org/abs/1907.05600,,,0,0,Energy-Based / Diffusion Models,,
DistilBERT,2019-10-02,https://arxiv.org/abs/1910.01108,"Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",0,1,Autoregressive / Transformer,0.66,
T5,2019-10-23,https://arxiv.org/abs/1910.10683,,,0,0,Autoregressive / Transformer,11.0,
StyleGAN2,2019-12-03,https://arxiv.org/abs/1912.04958,,,0,0,Generative Adversarial Network,,
NeRF,2020-03-19,https://arxiv.org/abs/2003.08934,,,0,0,General,,
GPT-3,2020-05-28,https://arxiv.org/abs/2005.14165,,,0,0,Autoregressive / Transformer,175.0,
DDPM,2020-06-19,https://arxiv.org/abs/2006.11239,,,0,0,Energy-Based / Diffusion Models,,
DDIM,2020-10-06,https://arxiv.org/abs/2010.02502,,,0,0,Energy-Based / Diffusion Models,,
Vision Transformer,2020-10-22,https://arxiv.org/abs/2010.11929,,,0,0,Autoregressive / Transformer,,
VQ-GAN,2020-12-17,https://arxiv.org/abs/2012.09841,,,0,0,Generative Adversarial Network,,
DALL.E,2021-02-24,https://arxiv.org/abs/2102.12092,,,0,0,Multimodal Models,12.0,
CLIP,2021-02-26,https://arxiv.org/abs/2103.00020,,,0,0,Multimodal Models,,
GPT-Neo,2021-03-21,https://github.com/EleutherAI/gpt-neo,,,0,0,Autoregressive / Transformer,2.7,
GPT-J,2021-06-10,https://github.com/kingoflolz/mesh-transformer-jax,,,0,0,Autoregressive / Transformer,6.0,
StyleGAN3,2021-06-23,https://arxiv.org/abs/2106.12423,,,0,0,Generative Adversarial Network,,
Codex,2021-07-07,https://arxiv.org/abs/2107.03374,,,0,0,Autoregressive / Transformer,,
ViT VQ-GAN,2021-10-09,https://arxiv.org/abs/2110.04627,,,0,0,Generative Adversarial Network,,
Megatron-Turing NLG,2021-10-11,https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/,,,0,0,Autoregressive / Transformer,530.0,
Gopher,2021-12-08,https://arxiv.org/abs/2112.11446,,,0,0,Autoregressive / Transformer,280.0,
GLIDE,2021-12-20,https://arxiv.org/abs/2112.10741,,,0,0,Multimodal Models,5.0,
Latent Diffusion,2021-12-20,https://arxiv.org/abs/2112.10752,,,0,0,Energy-Based / Diffusion Models,,
LaMDA,2022-01-20,https://arxiv.org/abs/2201.08239,,,0,0,Autoregressive / Transformer,137.0,
StyleGAN-XL,2022-02-01,https://arxiv.org/abs/2202.00273v2,,,0,0,Generative Adversarial Network,0.0,
GPT-NeoX,2022-02-02,https://github.com/EleutherAI/gpt-neox,,,0,0,Autoregressive / Transformer,20.0,
Chinchilla,2022-03-29,https://arxiv.org/abs/2203.15556v1,,,0,0,Autoregressive / Transformer,70.0,
PaLM,2022-04-05,https://arxiv.org/abs/2204.02311,,,0,0,Autoregressive / Transformer,540.0,
DALL.E 2,2022-04-13,https://arxiv.org/abs/2204.06125,,,0,0,Multimodal Models,3.5,
Flamingo,2022-04-29,https://arxiv.org/abs/2204.14198,,,0,0,Multimodal Models,80.0,
OPT,2022-05-02,https://arxiv.org/abs/2205.01068,,,0,0,Autoregressive / Transformer,175.0,
Imagen,2022-05-23,https://arxiv.org/abs/2205.11487,,,0,0,Multimodal Models,4.6,
Parti,2022-06-22,https://arxiv.org/abs/2206.10789,,,0,0,Multimodal Models,20.0,
BLOOM,2022-07-16,https://arxiv.org/abs/2211.05100,,,0,0,Autoregressive / Transformer,176.0,
Stable Diffusion,2022-08-22,https://stability.ai/blog/stable-diffusion-public-release,,,0,0,Multimodal Models,0.89,
ChatGPT,2022-11-30,https://chat.openai.com/,,,0,0,Autoregressive / Transformer,,
MUSE,2023-01-02,https://arxiv.org/abs/2301.00704,,,0,0,Multimodal Models,3.0,
MusicLM,2023-01-26,https://arxiv.org/abs/2301.11325,,,0,0,Multimodal Models,,
Dreamix,2023-02-02,https://arxiv.org/pdf/2302.01329.pdf,,,0,0,Multimodal Models,,
Toolformer,2023-02-09,https://arxiv.org/pdf/2302.04761.pdf,,,0,0,Autoregressive / Transformer,,
ControlNet,2023-02-10,https://arxiv.org/abs/2302.05543,,,0,0,Multimodal Models,,
LLaMA,2023-02-24,https://arxiv.org/abs/2302.13971,,,0,0,Autoregressive / Transformer,65.0,
PaLM-E,2023-03-06,https://arxiv.org/abs/2303.03378,,,0,0,Multimodal Models,562.0,
Visual ChatGPT,2023-03-08,https://arxiv.org/abs/2303.04671,,,0,0,Multimodal Models,,
Alpaca,2023-03-13,https://github.com/tatsu-lab/stanford_alpaca,,,1,0,Autoregressive / Transformer,,
GPT-4,2023-03-16,https://cdn.openai.com/papers/gpt-4.pdf,,,0,0,Autoregressive / Transformer,1000.0,
Luminous,2022-04-14,https://www.aleph-alpha.com/luminous,,,0,0,Autoregressive / Transformer,,
Flan-T5,2022-10-20,https://arxiv.org/abs/2210.11416,,,0,0,Autoregressive / Transformer,11.0,
Falcon,2023-03-17,https://falconllm.tii.ae/,,,0,0,Autoregressive / Transformer,40.0,
PaLM 2,2023-05-10,https://ai.google/discover/palm2/,,,0,0,Autoregressive / Transformer,340.0,
PanGu-Σ,2023-03-20,https://arxiv.org/abs/2303.10845,,,1,0,Autoregressive / Transformer,1085.0,
GPT-3.5,2022-11-30,,,,0,0,Autoregressive / Transformer,175.0,
Llama 2,2023-07-17,,,,0,0,Autoregressive / Transformer,70.0,
